{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f98e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:59:34.742059Z",
     "start_time": "2023-10-29T09:59:34.734061Z"
    }
   },
   "source": [
    "## LCEL and Chain Interface\n",
    "\n",
    "#### LCEL (LangChain Expression Language)  is a declarative method designed for succinctly describing chains.\n",
    "\n",
    "While LLMs can suffice in simple applications, complex applications often necessitate the chaining of LLMs with other components. LangChain furnishes two superior frameworks for this purpose:\n",
    "\n",
    "- **Chain interface**: The conventional method\n",
    "- **LCEL**: LangChain Expression Language\n",
    "\n",
    "For those constructing new applications, the use of `LCEL` is advocated. Notably, Chain can be integrated within LCEL, allowing for a hybrid utilization of both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bc104",
   "metadata": {},
   "source": [
    "# Advantages of LCEL\n",
    "\n",
    "The benefits of using **LCEL** include:\n",
    "\n",
    "- **Asynchronous, Batch, and Streaming Support**:  \n",
    "  Chains crafted in LCEL inherently cater to both synchronous and asynchronous interfaces, as well as batch and streaming capabilities. This flexibility simplifies the process of starting with a synchronous prototype and later transitioning it to an asynchronous streaming interface.\n",
    "\n",
    "- **Fallback in Chains**:  \n",
    "  With LCEL, any chain can readily incorporate fallbacks. This feature streamlines error management and fosters graceful handling.\n",
    "\n",
    "- **Parallel Processing**:  \n",
    "  LCEL-composed chains inherently support parallel processing for all its components. Given that LLM applications frequently incorporate lengthy API calls, the importance of parallelism cannot be understated.\n",
    "\n",
    "- **Seamless LangSmith Trace Integration**:  \n",
    "  An inherent trait of LCEL is the automatic logging of every step in LangSmith, ensuring optimum observability and debuggability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d0d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:41:34.795663Z",
     "start_time": "2023-10-29T09:41:12.856913Z"
    }
   },
   "source": [
    "!pip install langchain==0.0.321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387be4ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:45:48.805876Z",
     "start_time": "2023-10-29T09:45:48.800915Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"--------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb239a",
   "metadata": {},
   "source": [
    "## Describe the chain with \"LCEL\".\n",
    "#### The chain that connects \"prompt template â†’ model\" is written as \" prompt | model \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d61a7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:45:50.751736Z",
     "start_time": "2023-10-29T09:45:49.812751Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature = 0.5)\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee0a6e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:45:51.988843Z",
     "start_time": "2023-10-29T09:45:51.977731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Tell a joke about {topic}'))])\n",
       "| ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.5, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2226e",
   "metadata": {},
   "source": [
    "## Streaming responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eeff382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:45:56.455074Z",
     "start_time": "2023-10-29T09:45:53.696915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't programmers like nature?\n",
      "\n",
      "Because they prefer the indoors, where there are no bugs!"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"Programming\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ff5c4",
   "metadata": {},
   "source": [
    "# LangChain Components and the `Runnable` Protocol\n",
    "\n",
    "LangChain components implement the \"Runnable\" protocol. This protocol provides a standard interface for defining custom chains and invoking them in a standardized manner.\n",
    "\n",
    "## 4-1. Standard Interface\n",
    "\n",
    "The primary standard interfaces include:\n",
    "\n",
    "- **stream**: Stream back chunks of response.\n",
    "- **invoke**: Invoke chain with input.\n",
    "- **batch**: Invoke chain with a list of inputs.\n",
    "\n",
    "And there's a corresponding set of asynchronous methods:\n",
    "\n",
    "- **astream**: Asynchronously streams back a chunk of the response.\n",
    "- **ainvoke**: Asynchronously invokes the chain with an input.\n",
    "- **abatch**: Asynchronously invokes the chain with a list of inputs.\n",
    "- **astream_log**: Streams back intermediate steps in addition to the final response.\n",
    "\n",
    "## 4-2. Input Type and Output Type\n",
    "\n",
    "### Input Types\n",
    "\n",
    "Depending on the component, the types of input can be:\n",
    "\n",
    "- **Prompt**: Dictionary\n",
    "- **Retriever**: Single string\n",
    "- **LLM, ChatModel**: Single string, message list, PromptValue\n",
    "- **Tool**: Single string or dictionary (depends on the tool)\n",
    "- **OutputParser**: Output of LLM or ChatModel\n",
    "\n",
    "### Output Types\n",
    "\n",
    "Output types vary based on the component:\n",
    "\n",
    "- **LLM**: String\n",
    "- **ChatModel**: Chat message\n",
    "- **Prompt**: PromptValue\n",
    "- **Retriever**: List of documents\n",
    "- **Tool**: Depends on the tool\n",
    "- **OutputParser**: Depends on the parser\n",
    "\n",
    "### Checking Input and Output Schemas\n",
    "\n",
    "You can inspect the schemas for input and output types using:\n",
    "\n",
    "- **input_schema**: Input type schema (Pydantic)\n",
    "- **output_schema**: Output type schema (Pydantic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b3fdd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:46:45.395327Z",
     "start_time": "2023-10-29T09:46:45.388463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00534cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:47:07.514141Z",
     "start_time": "2023-10-29T09:47:07.507050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70bbfbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:47:21.849187Z",
     "start_time": "2023-10-29T09:47:21.831544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd49f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:45:58.273516Z",
     "start_time": "2023-10-29T09:45:58.258704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'}],\n",
       " 'definitions': {'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ee554e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:41:48.037384Z",
     "start_time": "2023-10-29T09:41:45.609133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the football team go to the bakery?\\n\\nBecause they needed a good roll!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Football\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8e34d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:41:51.030697Z",
     "start_time": "2023-10-29T09:41:48.039911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why did the two lovebirds break up?\\n\\nBecause they couldn't find any tweet-er love!\", additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"Why did the romance novel go to therapy?\\n\\nBecause it had commitment issues and couldn't put down its guard!\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"Love\"}, {\"topic\": \"Romance\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1f91dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:42:01.735621Z",
     "start_time": "2023-10-29T09:41:51.030697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why did the programmer quit his job?\\n\\nBecause he didn't get arrays!\", additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"Why don't scientists trust atoms when they travel?\\n\\nBecause they make up everything!\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"Coding\"}, {\"topic\": \"Travelling\"}], config={\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f3c38",
   "metadata": {},
   "source": [
    "### Async Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58446641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:42:05.006902Z",
     "start_time": "2023-10-29T09:42:01.741527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the satellite go to therapy?\n",
      "\n",
      "Because it felt like it was always being watched!"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"topic\": \"Satellites\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4f14b",
   "metadata": {},
   "source": [
    "### Async Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "642ef543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:42:08.994743Z",
     "start_time": "2023-10-29T09:42:06.770310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"topic\": \"Food\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720522f",
   "metadata": {},
   "source": [
    "### Async Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "664206fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:42:25.212820Z",
     "start_time": "2023-10-29T09:42:16.009974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", additional_kwargs={}, example=False),\n",
       " AIMessage(content='Why did the candy go to school?\\n\\nBecause it wanted to be a Smartie!', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch([{\"topic\": \"Food\"}, {\"topic\": \"Sweets\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca7524",
   "metadata": {},
   "source": [
    "### Async Stream with intermediate steps\n",
    "\n",
    "Useful for displaying progress to the user, working with intermediate results, and debugging chains. You can stream all steps (default) or include or exclude steps by name, tags, or metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9585d2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:34:13.450694Z",
     "start_time": "2023-10-29T09:34:09.769058Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\aiany\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\aiany\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafa4c7",
   "metadata": {},
   "source": [
    "Execute the Retriever chain and output intermediate steps using astream_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1189b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:48:13.824301Z",
     "start_time": "2023-10-29T09:48:09.911566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '128b9b46-7c1c-4428-b21f-4ad8839de566',\n",
      "            'logs': {},\n",
      "            'streamed_output': []}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'a45c106a-3b8c-47af-af18-805c0f998155',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2023-10-29T09:48:11.304',\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:context', 'FAISS', 'OpenAIEmbeddings'],\n",
      "            'type': 'retriever'}})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='Sonu is the creator of AI Anytime Youtube Channel')]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2023-10-29T09:48:11.828'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Son'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'u'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' is'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' the'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' creator'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' of'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' AI'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Any'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'time'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})\n",
      "----------------------------------------\n",
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': {'output': 'Sonu is the creator of AI Anytime.'}})\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "template = \"\"\"Please answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts([\"Sonu is the creator of AI Anytime Youtube Channel\"], embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever.with_config(run_name='Docs'), \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "async for chunk in retrieval_chain.astream_log(\"Who is the creator of AI Anytime?\", include_names=['Docs']):\n",
    "    print(\"-\"*40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a18759",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "\n",
    "\"RunnableParallel\" allows each element to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a6e4db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:50:40.731704Z",
     "start_time": "2023-10-29T09:50:40.723288Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "chain1 = ChatPromptTemplate.from_template(\"Tell a joke about {topic}\") | model\n",
    "chain2 = ChatPromptTemplate.from_template(\"Write a short (2 line) poem about {topic}\") | model\n",
    "combined = RunnableParallel(joke=chain1, poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb7085c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:51:16.921592Z",
     "start_time": "2023-10-29T09:51:13.214684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 3.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Why did the AI go on a diet?\\n\\nBecause it had too many bytes!'),\n",
       " AIMessage(content='Why was the math book sad?\\n\\nBecause it had too many problems!')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chain1.batch([{\"topic\": \"AI\"}, {\"topic\": \"Math\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42386966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:52:21.291731Z",
     "start_time": "2023-10-29T09:52:18.287272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Science, the compass of human thought,\\nUnveiling mysteries, the world's wisdom sought.\"),\n",
       " AIMessage(content=\"Golden fruit, sweet delight,\\nMango's taste, pure summer's light.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chain2.batch([{\"topic\": \"Science\"}, {\"topic\": \"Mango\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c6f1d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T09:53:14.695511Z",
     "start_time": "2023-10-29T09:53:11.944824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 2.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'joke': AIMessage(content='Why did the AI go on a diet?\\n\\nBecause it heard it was gaining too many bytes!'),\n",
       "  'poem': AIMessage(content='Artificial minds, algorithms thrive,\\nUnleashing wonders, as they strive.')},\n",
       " {'joke': AIMessage(content='Why did the mountain go to the gym?\\n\\nBecause it wanted to get peak physical condition!'),\n",
       "  'poem': AIMessage(content=\"Majestic peaks touch the sky,\\nNature's strength, standing high.\")}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# combined\n",
    "combined.batch([{\"topic\": \"AI\"}, {\"topic\": \"Mountains\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501126ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
